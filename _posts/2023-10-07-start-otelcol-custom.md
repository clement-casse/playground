---
layout: single
categories: [ otelcol-custom ]
title: "Building a Custom OpenTelemetry Collector with Nix - A Starting Point"
tags: [ opentelemetry, otelcol, nix-flake ]
---

In this post, I'll present how to combine *Nix Flakes* with *OpenTelemetry Collector Builder* to create a custom Collector binary only with the components you need.
<!--more-->

> Before that, here is the obligatory picture acting as cover for this post representing a *"halfling assembling a telescope with a blueprint"* that is generated by AI.
> I wanted to illustrate the assembly process of a telescope that is the logo of OpenTelemetry, and the AI returned me a cute little halfling.
{: .notice}

{% include figure
    image_path="/assets/images/halfling-assembling-telescope.jpg"
    alt="AI Generated illustration of a halfling assembling a telescope"
    caption="Image generated by AI with prompt \"halfling assembling a telescope with a blueprint\"."
%}

# Context

## The Big Picture of OpenTelemetry Collector

OpenTelemetry is one of the [CNCF incubating projects](https://www.cncf.io/projects/opentelemetry/), it is a big open-source project that aims to normalize monitoring of Cloud applications.
Unlike [Prometheus](https://www.cncf.io/projects/prometheus/) or [Jaeger](https://www.cncf.io/projects/jaeger/) which propose technical solutions to store and query respectively metrics and traces emitted by software in Cloud environments, OpenTelemetry takes a complementary approach by proposing a standardized approach for collecting and processing monitoring data before sending them to a particular backend.

Indeed, OpenTelemetry describes itself as:

> OpenTelemetry is a collection of APIs, SDKs, and tools.
> Use it to instrument, generate, collect, and export telemetry data (metrics, logs, and traces) to help you analyse your software’s performance and behaviour.

And, among the *tools* category, lies the *OpenTelemetry Collector*: a standalone process described as a vendor-agnostic way to receive, process and export telemetry data.
This *collector* materializes as different kinds of modules chained together to form a processing pipeline for the different monitoring signals (traces, metrics, logs):

- `receivers` are modules that ingest data in the pipeline, their role is to transpose some specific format in the OpenTelemetry format so they can be processed by further stages in the pipeline.
- `processors` are modules that alter telemetry data that already is in the OpenTelemetry format, this alteration can be like adding/removing some attribute to the data, or simply to propagate the data further in the pipeline or not ...
- `exporters` are modules that convert OpenTelemetry data to another format to send data to a custom backend like, e.g. Jaeger, Amazon CloudWatch, Prometheus, a file in the JSON or CSV format, ...

Other modules exist like `extensions` and `connectors` which will not be detailed in this post but, for the scope of what is presented here, have a similar behaviour.

When an OpenTelemetry collector is started, it will take config files defining pipelines and instantiate them with the modules that are packaged in the collector.
The following image represents a screenshot of the visual tool [`otelbin.io`][otelbin] that helps understanding OpenTelemetry Pipelines with an visual representation of the collector configuration file.
In this picture the code on the left side is one of the most basic configuration file for an OpenTelemetry collector containing the `otlp` receiver and exporter as well as the `batch` processor, the right side displays the pipelines defined under the section `service` > `pipelines`.

{% include figure
    image_path="/assets/images/basic-otelcol-pipelines.png"
    alt="Screenshot of the landing page of <https://www.otelbin.io> presenting a YAML configuration along with its visual representation of multiple pipelines that display receivers, processors and collectors"
    caption="Screenshot of the OtelBin.io tool with the most basic example"
%}

The configuration from this illustration does not really do a thing, though: data is not transformed just capture and sent it batches in the same protocol as it was received.
While, this kind of configuration can be used by some agents that forward telemetry to another collector, this other collector will have to transform data.
And, to transform data, collectors have to implement different modules that support all the operations and technology users might want to deal with in their monitoring pipelines.

The number of modules for OpenTelemetry Collector is high and ever increasing as demonstrates the GitHub repository [`open-telemetry/opentelemetry-collector-contrib`](https://github.com/open-telemetry/opentelemetry-collector-contrib) which lists module contributions from the community.
At the time of writing, in this repository, there is **90 receiver modules**, **24 processor modules** and **47 exporter modules**.

Among the companies that have adopted OpenTelemetry, many of them decided to create their own collector only with a selection of modules they want to support in their system.
In the following, we show a list of *distributions* of OpenTelemetry Collectors:
  - [OpenTelemetry Core Collector](https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/otelcorecol)
  - [OpenTelemetry Collector Contrib](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/cmd/otelcontribcol)
  - [AWS Observability Collector](https://github.com/aws-observability/aws-otel-collector)
  - [Sumo Logic Distribution for OpenTelemetry Collector](https://github.com/SumoLogic/sumologic-otel-collector)

## Creating a Custom Distribution of OpenTelemetry Collector

> If you are already familiar with how OpenTelemetry Collectors are built, and have already run `ocb` with a custom manifest, feel free to skip this part.
{: .notice}

With this ever-increasing number of modules involved in the code of the OpenTelemetry Collector, it becomes evident that we can speak about **Distributions** of OpenTelmetry Collectors.
We have already seen examples of big actors in the field of observability cherry-picking modules from the community to form a collector compliant with their ecosystem.
Also, it may be a strategic choice for designers of managed services to create their own `receivers`/`exporter` to ease configuration for their end users.

To support all of these scenarios, the OpenTelemetry Collector developers decided to structure the code base so that making a collector distribution is trivial.
The official documentation present [this process][opentelemetry-docs-build-otelcol] and one of the most prominent contributors of the project also made a [Medium article covering this topic more in depth][krohling-build-own-otelcol].
The process described in these websites is the process used by OpenTelemetry developers to build their [`otelcorecol`](https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/otelcorecol) and [`otelcontribcol`](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/cmd/otelcontribcol).

This method revolves around a tool called *OpenTelemetry Collector Builder* (also designated as `ocb` or `builder` in the latter).
This tool leverage automatic code generation and how Go Modules work:

1. All elements taking part in the pipelines of the collector are exposed as [Go modules](https://go.dev/blog/using-go-modules).
2. Depending on their role in the pipeline (`receiver`, `exporter`, `processor`, ...), each of the module implements some interface and exposes some metadata.
3. `ocb` requires a list of references to the modules we want to have in the collector as well as a configuration to build the collector.
4. With the previous pieces of information, `ocb` can generate the code base of a Go Module wiring all the referenced modules together in a single binary.

Therefore, to build a collector with `ocb`, you will basically need two things:

1. Having a Go version compatible with the current OpenTelemetry version installed.
2. Having a "manifest file" that describes what module the collector will embed.

About the manifest file, it takes the form of a YAML file that have to follow [these specifications (not always up to date)](https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/builder#configuration).
The following code present this YAML file with additional comments for explaining how the manifest file work.

```yaml
# dist key lists all the parameter that will be used to build
# the binary of the collector: the following keys provide a
# name for the binary, a description that will be printed when
# calling the `--help` option and a path where the code 
# generation will be performed.
dist:
  name: otelcol-custom-dev
  description: Local OpenTelemetry Collector binary
  output_path: /tmp/dist

# the following keys provide references to the go modules we
# want to implement in our custom OpenTelemetry Collector.
# Supported Keys are: `receivers`, `processors`, `exporters`,
# `extensions`, `connectors`.
exporters:
  - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/exporter/alibabacloudlogserviceexporter v0.86.0
  - gomod: go.opentelemetry.io/collector/exporter/debugexporter v0.86.0

receivers:
  - gomod: go.opentelemetry.io/collector/receiver/otlpreceiver v0.86.0

processors:
  - gomod: go.opentelemetry.io/collector/processor/batchprocessor v0.86.0

# Also the `replaces` key exists expecting a list of replace
# directives as defined in Go Modules, but it won't be 
# tackeled in this post.
```

Therefore, the build process of OpenTelemetry Collectors leverages the Go environment with custom tools that do automatic code generation.
This is not a traditional approach to build such application, however this greatly increase the composability and the distribution aspect of the OpenTelemetry Collector.
This manifest file also seems to open the opportunity for adding a custom modules among other On-The-Shelf modules to truely create a custom pipeline.
While this is the intent of the [**otelcol-custom** playground project](/playground/otelcol-custom/), adding custom code part of the collector is not part of the scope of this post.

The next part will tackle, how to use Nix Flakes to create a reproductible environment for building OpenTelemetry Collectors that accomodate this custom build process.

## Nix Flakes

In another hand, there is [**Nix**](https://nixos.org/).
And behind this name lies a lot of different concepts that are too overwhelming to cover in one single post, indeed Nix is a *package manager*, but also a *language*, and it can also be an *Operating System* on its own.
As I do not want, nor have the knowledge to go into the rabbit hole of *Nix* I am going to only scratch the surface in this post.
In particular, I will focus on the concept of Nix Flakes and present how to use them to build a truly reproducible development environment that would work on my local machine exactly as it would work on a *Continuous Integration* pipeline or on someone else machine (as long as nix is installed).

> [Flakes are] a new Nix feature that improves reproducibility, composability and usability in the Nix ecosystem.
> 
> *-- https://www.tweag.io/blog/2020-05-25-flakes/*

# Building an OpenTelemetry Collector with a Nix Flake

## Motivation

## 

# References

- [OTelBin.io: Tool for visual representation of OpenTelemetry collector pipelines][otelbin]
- [OpenTelemetry Documentation Page: Building a custom collector][opentelemetry-docs-build-otelcol]
- [Medium Article: Building your own OpenTelemetry Collector distribution by Juraci Paixão Kröhling][krohling-build-own-otelcol]
- [Juraci Paixão Kröhling: OpenTelemetry Collector deployment patterns @ KubeCon North America 2021][otelcol-deploy-patterns]

[otelbin]: https://www.otelbin.io
[opentelemetry-docs-build-otelcol]: https://opentelemetry.io/docs/collector/custom-collector/
[krohling-build-own-otelcol]: https://medium.com/opentelemetry/building-your-own-opentelemetry-collector-distribution-42337e994b63
[otelcol-deploy-patterns]: https://github.com/jpkrohling/opentelemetry-collector-deployment-patterns
